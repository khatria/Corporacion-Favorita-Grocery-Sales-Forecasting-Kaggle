{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6MoJYgsKldg"
   },
   "source": [
    "<h1> Final submission </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMMbGWKqKe2I",
    "outputId": "b827fd5d-2db9-4efb-aa44-103a3b6eb1d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /opt/conda/lib/python3.7/site-packages (2.2.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.23.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /opt/conda/lib/python3.7/site-packages (from category_encoders) (1.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->category_encoders) (0.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.21.1->category_encoders) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6U4QnHr-Ke2Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import calendar\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from joblib import dump, load\n",
    "from sklearn import preprocessing\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zd9gR_5HKe2Y"
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def cat_encoding(cat_data, category):\n",
    "  '''\n",
    "  This function takes a df and the category and generate\n",
    "  binary encoded vectors for the same\n",
    "  '''\n",
    "  encoder = ce.BinaryEncoder()\n",
    "  return encoder.fit_transform(cat_data[category]).values\n",
    "\n",
    "def generate_cat_features(sales_data):\n",
    "  '''\n",
    "  This function uses cat_encoding function and does binary encoding for all the categorical variables\n",
    "  '''\n",
    "  items_df = pd.read_csv('items.csv')\n",
    "  stores_df = pd.read_csv('stores.csv')\n",
    "\n",
    "  class_family_df = pd.DataFrame(sales_data['item_nbr']).merge(items_df[['item_nbr', 'class', 'family', 'perishable']], on = 'item_nbr', how = 'left')\n",
    "  class_family_df['class'] = class_family_df['class'].astype('str')\n",
    "  class_family_df['item_nbr'] = class_family_df['item_nbr'].astype('str')\n",
    "\n",
    "  store_detail_df = pd.DataFrame(sales_data['store_nbr']).merge(stores_df[['store_nbr', 'state', 'city', 'type', 'cluster']], on = 'store_nbr', how = 'left')\n",
    "  store_detail_df['store_nbr'] = store_detail_df['store_nbr'].astype('str')\n",
    "  store_detail_df['cluster'] = store_detail_df['cluster'].astype('str')\n",
    "\n",
    "  class_array = cat_encoding(class_family_df, 'class')\n",
    "  family_array = cat_encoding(class_family_df, 'family')\n",
    "  item_array = cat_encoding(class_family_df, 'item_nbr')\n",
    "\n",
    "\n",
    "  store_array = cat_encoding(store_detail_df, 'store_nbr')\n",
    "  store_state_array = cat_encoding(store_detail_df, 'state')\n",
    "  store_city_array = cat_encoding(store_detail_df, 'city')\n",
    "  store_type_array = cat_encoding(store_detail_df, 'type')\n",
    "  store_cluster_array = cat_encoding(store_detail_df, 'cluster')\n",
    "\n",
    "  return class_array, family_array, item_array, store_array, store_state_array, store_city_array, store_type_array, store_cluster_array, class_family_df\n",
    "\n",
    "def get_data(data, dt_end, days, period, freq='D'):\n",
    "  '''\n",
    "  This function gives us the selected columns based on a range of dates passed.\n",
    "  '''\n",
    "  return data[[str(col)[0:10] for col in pd.date_range(dt_end - datetime.timedelta(days = days), periods = period, freq = freq)]]\n",
    "\n",
    "def average(data):\n",
    "  '''\n",
    "  Here we are calculating simple average\n",
    "  '''\n",
    "  return np.mean(data, axis = 1)\n",
    "\n",
    "def weighted_moving_average(data):\n",
    "  '''\n",
    "  This function computes weighted moving average, \n",
    "  higher weights are given to recent observations.\n",
    "  '''\n",
    "  data = data.values\n",
    "  weight_len = data.shape[1]\n",
    "  denom = (weight_len *(weight_len + 1))/2\n",
    "  weights = [i+1/denom for i in range(weight_len)]\n",
    "  data = average(data * weights)\n",
    "  return data\n",
    "\n",
    "def feature_engg_sales(data, end_date, prefix):\n",
    "  '''\n",
    "  This function generates feature dictionary for train, cv, test\n",
    "  Features generated are:\n",
    "  moving average, weighted moving average, standard deviation observed, \n",
    "  moving average of DOW, weighted moving average of DOW, having total sales day,\n",
    "  last sales day in n days, first sales day in n days\n",
    "  '''\n",
    "  days_list = [3, 7, 16, 30, 60, 120] # These are the list of days used for extracting above mentioned features \n",
    "  #feature_dict = {}\n",
    "  feature_dict = {'{}_average_{}_days'.format(prefix, days): average(get_data(data, end_date, days, days).values)  for days in days_list}\n",
    "  feature_dict.update({'{}_WMA_{}_days'.format(prefix, days): weighted_moving_average(get_data(data, end_date, days, days)) for days in days_list})\n",
    "  feature_dict.update({'{}_std_{}_days'.format(prefix, days) : get_data(data, end_date, days, days).std(axis = 1).values for days in days_list})\n",
    "  feature_dict.update({'{}_6avgdow_{}_days'.format(prefix, day) : get_data(data, end_date, 42 - day, 6, freq = '7D').mean(axis =1).values for day in range(7)})\n",
    "  feature_dict.update({'{}_20avgdow_{}_days'.format(prefix, day) : get_data(data, end_date, 140 - day, 20, freq = '7D').mean(axis =1).values for day in range(7)})\n",
    "  feature_dict.update({'{}_6WMAdow_{}_days'.format(prefix, day) : weighted_moving_average(get_data(data, end_date, 42 - day, 6, freq = '7D')) for day in range(7)})\n",
    "  feature_dict.update({'{}_20WMAdow_{}_days'.format(prefix, day) : weighted_moving_average(get_data(data, end_date, 140 - day, 20, freq = '7D')) for day in range(7)})\n",
    "  feature_dict.update({'{}_has_sale_day_{}'.format(prefix, days) : (get_data(data, end_date, days, days) > 0).sum(axis = 1).values for days in days_list})\n",
    "  feature_dict.update({'{}_last_has_sale_day_{}'.format(prefix, days) : days - ((get_data(data, end_date, days, days) > 0) * np.arange(days)).max(axis = 1).values for days in days_list})\n",
    "  feature_dict.update({'{}_first_has_sale_day_{}'.format(prefix, days) : ((get_data(data, end_date, days, days) > 0) * np.arange(days, 0, -1)).max(axis = 1).values for days in days_list})\n",
    "\n",
    "  return feature_dict\n",
    "\n",
    "def feature_engg_promo(data, class_array, family_array, item_array, store_array, store_state_array, store_city_array, store_type_array, store_cluster_array, class_family_df, end_date, prefix):\n",
    "    '''\n",
    "    This function uses promo information and categorical array to create features\n",
    "    features created are---\n",
    "    promo: total_promo, future promo information, promo days in 15 days, last promo in 15 days, first promo in 15 days\n",
    "    categorical: class, item, store, family, city, state, clsuter, type \n",
    "    '''\n",
    "    days_list = [16, 30, 60, 120]\n",
    "    feature_dict = {'{}_totalpromo_{}_days'.format(prefix, days) : get_data(data, end_date, days, days).sum(axis = 1).values for days in days_list}\n",
    "    feature_dict.update({'{}_totalpromoafter_{}_days'.format(prefix, days) : get_data(data, end_date + timedelta(days = 16), 16, days).sum(axis = 1).values for days in [5, 10, 15]})\n",
    "    feature_dict.update({'{}_promo_{}_day'.format(prefix, abs(day - 1)): get_data(data, end_date, day, 1).values.ravel() for day in range(-15, 1)})\n",
    "    feature_dict.update({'promo_day_in_15_days' : (get_data(data, end_date + timedelta(days=16), 15, 15) > 0).sum(axis = 1).values})\n",
    "    feature_dict.update({'last_promo_day_in_15_days' : 15 - ((get_data(data, end_date + timedelta(days=16), 15, 15) > 0) * np.arange(15)).max(axis = 1).values})\n",
    "    feature_dict.update({'firt_promo_day_in_15_days' : ((get_data(data, end_date + timedelta(days=16), 15, 15) > 0) * np.arange(15, 0, -1)).max(axis = 1).values})\n",
    "    feature_dict.update({'class_{}'.format(i+1) : class_array[:, i] for i in range(class_array.shape[1])})\n",
    "    feature_dict.update({'item_{}'.format(i+1) : item_array[:, i] for i in range(item_array.shape[1])})\n",
    "    feature_dict.update({'store_{}'.format(i+1) : store_array[:, i] for i in range(store_array.shape[1])})\n",
    "    feature_dict.update({'family_{}'.format(i+1) : family_array[:, i] for i in range(family_array.shape[1])})\n",
    "    feature_dict.update({'city_{}'.format(i+1) : store_city_array[:, i] for i in range(store_city_array.shape[1])})\n",
    "    feature_dict.update({'state_{}'.format(i+1) : store_state_array[:, i] for i in range(store_state_array.shape[1])})\n",
    "    feature_dict.update({'cluster_{}'.format(i+1) : store_cluster_array[:, i] for i in range(store_cluster_array.shape[1])})\n",
    "    feature_dict.update({'type_{}'.format(i+1) : store_type_array[:, i] for i in range(store_type_array.shape[1])})\n",
    "    feature_dict.update({'perishable' : class_family_df['perishable'].values})\n",
    "    \n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvNeuLKiKe2d"
   },
   "outputs": [],
   "source": [
    "def final_fun_1(X):\n",
    "  '''\n",
    "  This function takes raw input, generate features using the raw input and make prediction for the test file.\n",
    "  '''\n",
    "  print('Generating sales and promo data for feature engg')\n",
    "  X.loc[(X.unit_sales<0),'unit_sales'] = 0\n",
    "  X['unit_sales'] =  X['unit_sales'].apply(lambda x : np.log1p(x))\n",
    "  X = X.replace(to_replace = [False, True], value = [0, 1])\n",
    "\n",
    "  sales_data = X.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)\n",
    "  sales_data.columns = sales_data.columns.get_level_values(1)\n",
    "  sales_data = sales_data.reset_index()\n",
    "\n",
    "  train_promo = X.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(level=-1).fillna(0)\n",
    "  train_promo.columns = train_promo.columns.get_level_values(1)\n",
    "\n",
    "  test = pd.read_csv('test.csv')\n",
    "  test = test.replace(to_replace = [False, True], value = [0, 1])\n",
    "\n",
    "  test_promo = test.set_index(['store_nbr', 'item_nbr', 'date'])[[\"onpromotion\"]].unstack(level=-1).fillna(0)\n",
    "  test_promo.columns = test_promo.columns.get_level_values(1)\n",
    "  test_promo = test_promo.reindex(train_promo.index).fillna(0)\n",
    "\n",
    "  promo_data = pd.concat([train_promo, test_promo], axis=1)\n",
    "  promo_data = promo_data.reset_index()\n",
    "  del test, train_promo, test_promo\n",
    "  print('Data Collected!!!')\n",
    "  print('Shape of sales and promo data is: {} and {}'.format(sales_data.shape, promo_data.shape))\n",
    "\n",
    "  print('Generating categorical variables features')\n",
    "  class_array, family_array, item_array, store_array, store_state_array, store_city_array, store_type_array, store_cluster_array, class_family_df = generate_cat_features(sales_data)\n",
    "  print('Categorical variables features generated')\n",
    "  \n",
    "  print('Extracting features for training using sales information')\n",
    "  x_lst, y_lst = [], []\n",
    "  num_of_intervals = 8\n",
    "  dates = [date(2017, 5, 31) + timedelta(days=7 * interval) for interval in range(num_of_intervals)]\n",
    "  for train_date in dates:\n",
    "    train_dict = feature_engg_sales(sales_data, train_date,'item_store')\n",
    "    x_lst.append(pd.DataFrame(train_dict, index = [i for i in range(len(list(train_dict.values())[0]))]))\n",
    "    y_lst.append(sales_data[[str(col)[0:10] for col in pd.date_range(train_date, periods = 16)]].values)\n",
    "\n",
    "  train_item_store_x = pd.concat(x_lst, axis=0)\n",
    "  train_y = np.concatenate(y_lst, axis=0)\n",
    "  del x_lst, y_lst\n",
    "  #print(train_item_store_x.shape, train_y.shape)\n",
    "\n",
    "  print('Extracting features for training using promo information')\n",
    "  x_lst = []\n",
    "  num_of_intervals = 8\n",
    "  dates = [date(2017, 5, 31) + timedelta(days=7 * interval) for interval in range(num_of_intervals)]\n",
    "  for train_date in dates:\n",
    "    train_dict = feature_engg_promo(promo_data, class_array, family_array, item_array, store_array, store_state_array, store_city_array, store_type_array, store_cluster_array, class_family_df, train_date,'item_store')\n",
    "    x_lst.append(pd.DataFrame(train_dict, index = [i for i in range(len(list(train_dict.values())[0]))]))\n",
    "\n",
    "  train_item_store_x1 = pd.concat(x_lst, axis=0)\n",
    "  del x_lst\n",
    "  #print(train_item_store_x1.shape)\n",
    "  train_x = train_item_store_x.reset_index(drop = True).merge(train_item_store_x1.reset_index(drop = True), left_index=True, right_index=True)\n",
    "  del train_item_store_x, train_item_store_x1\n",
    "  [train_x[col].update((train_x[col] - train_x[col].min()) / (train_x[col].max() - train_x[col].min())) for col in train_x.columns]\n",
    "  print('Shape of train_x and corresponding train_y is {} & {}'.format(train_x.shape, train_y.shape))\n",
    "\n",
    "  print('Extracting features for prediction on test data using sales information')\n",
    "  test_date = date(2017, 8, 16)\n",
    "  test_dict = feature_engg_sales(sales_data, test_date, 'item_store')\n",
    "  test_item_store_x = pd.DataFrame(test_dict, index = [i for i in range(len(list(test_dict.values())[0]))])\n",
    "\n",
    "  print('Extracting features for prediction on test data using promo information')\n",
    "  test_dict = feature_engg_promo(promo_data, class_array, family_array, item_array, store_array, store_state_array, store_city_array, store_type_array, store_cluster_array, class_family_df, test_date, 'item_store')\n",
    "  test_item_store_x1 = pd.DataFrame(test_dict, index = [i for i in range(len(list(test_dict.values())[0]))])\n",
    "  test_x = test_item_store_x.reset_index(drop = True).merge(test_item_store_x1.reset_index(drop = True), left_index=True, right_index=True)\n",
    "  [test_x[col].update((test_x[col] - test_x[col].min()) / (test_x[col].max() - test_x[col].min())) for col in test_x.columns]\n",
    "  print('Shape of test_x is {}'.format(test_x.shape))\n",
    "\n",
    "  print('Making predictions using the pre trained model')\n",
    "  test_pred = []\n",
    "  dtest = xgb.DMatrix(test_x)\n",
    "  for i in range(16):\n",
    "    #print('Generating results for forecasting step{}'.format(i+1))\n",
    "    model = xgb.Booster()\n",
    "    filename = 'step{}_model'.format(i+1)\n",
    "    model.load_model(filename)\n",
    "    test_pred.append(model.predict(dtest))\n",
    "    \n",
    "  print('Prediction done on test data... generating final output')\n",
    "  y_test = np.array(test_pred).transpose()\n",
    "  pred_df = pd.DataFrame(y_test, columns = pd.date_range('2017-08-16', periods = 16))\n",
    "  pred_df = sales_data[['item_nbr', 'store_nbr']].merge(pred_df, left_index=True, right_index=True)\n",
    "  pred_df = pred_df.melt(id_vars=['item_nbr', 'store_nbr'], var_name='date', value_name='unit_sales')\n",
    "  pred_df['unit_sales'] = pred_df['unit_sales'].apply(lambda x : np.expm1(x))\n",
    "  print('Prediction df generated, loading test file and merging results with test file')\n",
    "  test_df = pd.read_csv('test.csv')\n",
    "  test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "  test_df = test_df.merge(pred_df[['item_nbr', 'store_nbr', 'date', 'unit_sales']], on = ['date', 'store_nbr', 'item_nbr'], how = 'left')\n",
    "  test_df['unit_sales'] = test_df['unit_sales'].clip(lower = 0)\n",
    "  test_df = test_df.fillna(0)\n",
    "\n",
    "  return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uiMO_uWOKe2j"
   },
   "outputs": [],
   "source": [
    "def final_fun_2(X):\n",
    "  '''\n",
    "  This function takes raw input, generate features using the raw input and generate score using the actual labels \n",
    "  and the predicted one by the model.\n",
    "  '''\n",
    "  print('Generating sales and promo data for feature engg')\n",
    "  X.loc[(X.unit_sales<0),'unit_sales'] = 0\n",
    "  X['unit_sales'] =  X['unit_sales'].apply(lambda x : np.log1p(x))\n",
    "  X = X.replace(to_replace = [False, True], value = [0, 1])\n",
    "\n",
    "  sales_data = X.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)\n",
    "  sales_data.columns = sales_data.columns.get_level_values(1)\n",
    "  sales_data = sales_data.reset_index()\n",
    "\n",
    "  train_promo = X.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(level=-1).fillna(0)\n",
    "  train_promo.columns = train_promo.columns.get_level_values(1)\n",
    "\n",
    "  test = pd.read_csv('test.csv')\n",
    "  test = test.replace(to_replace = [False, True], value = [0, 1])\n",
    "\n",
    "  test_promo = test.set_index(['store_nbr', 'item_nbr', 'date'])[[\"onpromotion\"]].unstack(level=-1).fillna(0)\n",
    "  test_promo.columns = test_promo.columns.get_level_values(1)\n",
    "  test_promo = test_promo.reindex(train_promo.index).fillna(0)\n",
    "\n",
    "  promo_data = pd.concat([train_promo, test_promo], axis=1)\n",
    "  promo_data = promo_data.reset_index()\n",
    "  del test, train_promo, test_promo\n",
    "  print('Data Collected!!!')\n",
    "  print('Shape of sales and promo data is: {} and {}'.format(sales_data.shape, promo_data.shape))\n",
    "\n",
    "  print('Generating categorical variables features')\n",
    "  class_array, family_array, item_array, store_array, store_state_array, store_city_array, store_type_array, store_cluster_array, class_family_df = generate_cat_features(sales_data)\n",
    "  print('Categorical variables features generated')\n",
    "  \n",
    "  print('Extracting features for training using sales information')\n",
    "  x_lst, y_lst = [], []\n",
    "  num_of_intervals = 8\n",
    "  dates = [date(2017, 5, 31) + timedelta(days=7 * interval) for interval in range(num_of_intervals)]\n",
    "  for train_date in dates:\n",
    "    train_dict = feature_engg_sales(sales_data, train_date,'item_store')\n",
    "    x_lst.append(pd.DataFrame(train_dict, index = [i for i in range(len(list(train_dict.values())[0]))]))\n",
    "    y_lst.append(sales_data[[str(col)[0:10] for col in pd.date_range(train_date, periods = 16)]].values)\n",
    "\n",
    "  train_item_store_x = pd.concat(x_lst, axis=0)\n",
    "  train_y = np.concatenate(y_lst, axis=0)\n",
    "  del x_lst, y_lst\n",
    "  #print(train_item_store_x.shape, train_y.shape)\n",
    "\n",
    "  print('Extracting features for training using promo information')\n",
    "  x_lst = []\n",
    "  num_of_intervals = 8\n",
    "  dates = [date(2017, 5, 31) + timedelta(days=7 * interval) for interval in range(num_of_intervals)]\n",
    "  for train_date in dates:\n",
    "    train_dict = feature_engg_promo(promo_data, class_array, family_array, item_array, store_array, store_state_array, store_city_array, store_type_array, store_cluster_array, class_family_df, train_date,'item_store')\n",
    "    x_lst.append(pd.DataFrame(train_dict, index = [i for i in range(len(list(train_dict.values())[0]))]))\n",
    "\n",
    "  train_item_store_x1 = pd.concat(x_lst, axis=0)\n",
    "  del x_lst\n",
    "  #print(train_item_store_x1.shape)\n",
    "  train_x = train_item_store_x.reset_index(drop = True).merge(train_item_store_x1.reset_index(drop = True), left_index=True, right_index=True)\n",
    "  del train_item_store_x, train_item_store_x1\n",
    "  [train_x[col].update((train_x[col] - train_x[col].min()) / (train_x[col].max() - train_x[col].min())) for col in train_x.columns]\n",
    "  print('Shape of train_x and corresponding train_y is {} & {}'.format(train_x.shape, train_y.shape))\n",
    "\n",
    "  print('Extracting features for prediction on data using sales information')\n",
    "  cv_date = date(2017, 7, 26)\n",
    "  cv_dict = feature_engg_sales(sales_data, cv_date, 'item_store')\n",
    "  cv_item_store_x = pd.DataFrame(cv_dict, index = [i for i in range(len(list(cv_dict.values())[0]))])\n",
    "\n",
    "  print('Extracting features for prediction on data using promo information')\n",
    "  cv_dict = feature_engg_promo(promo_data, class_array, family_array, item_array, store_array, store_state_array, store_city_array, store_type_array, store_cluster_array, class_family_df, cv_date, 'item_store')\n",
    "  cv_item_store_x1 = pd.DataFrame(cv_dict, index = [i for i in range(len(list(cv_dict.values())[0]))])\n",
    "  cv_x = cv_item_store_x.reset_index(drop = True).merge(cv_item_store_x1.reset_index(drop = True), left_index=True, right_index=True)\n",
    "  [cv_x[col].update((cv_x[col] - cv_x[col].min()) / (cv_x[col].max() - cv_x[col].min())) for col in cv_x.columns]\n",
    "  print('Shape of data on which we will predict is {}'.format(cv_x.shape))\n",
    "  print('Generating true labels for the data....')\n",
    "  cv_y = sales_data[[str(col)[0:10] for col in pd.date_range(cv_date, periods = 16)]].values\n",
    "\n",
    "  print('Making predictions using the pre trained model')\n",
    "  cv_pred = []\n",
    "  dcv = xgb.DMatrix(cv_x)\n",
    "  for i in range(16):\n",
    "   # print('Generating results for forecasting step{}'.format(i+1))\n",
    "    model = xgb.Booster()\n",
    "    filename = 'step{}_model'.format(i+1)\n",
    "    model.load_model(filename)\n",
    "    cv_pred.append(model.predict(dcv))\n",
    "\n",
    "  print('Predition done, calculating Normalized Weighted Root Mean Squared Log Error!!!')\n",
    "  items_df = pd.read_csv('items.csv')\n",
    "  cv_weights = pd.DataFrame(sales_data['item_nbr']).merge(items_df[['item_nbr', 'perishable']], on = 'item_nbr', how = 'left')['perishable'] * 0.25 + 1\n",
    "  cv_yhat = np.array(cv_pred).transpose()\n",
    "  log_error = (np.log1p(cv_yhat) - np.log1p(cv_y)) ** 2\n",
    "  error = log_error.sum(axis = 1) * cv_weights\n",
    "  rmsle = np.sqrt(error.sum() / cv_weights.sum())\n",
    "\n",
    "  return rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBZErJYfKe2q"
   },
   "outputs": [],
   "source": [
    "def flow():\n",
    "  print('Calling Function 1 which will return predictions on test file!!!!')\n",
    "  print('*'*75)\n",
    "  print('Loading raw data!!!')\n",
    "  train_df = pd.read_csv('train.csv', skiprows=range(1, 101688780))\n",
    "  predictions = final_fun_1(train_df)\n",
    "  print(predictions.head())\n",
    "  predictions[['id', 'unit_sales']].to_csv('final_submission.csv', index = False)\n",
    "  print('\\n\\n')\n",
    "  print('Calling Function 2 which will return NWRMSLE!!!!')\n",
    "  print('*'*75)\n",
    "  print('Loading raw data!!!')\n",
    "  train_df = pd.read_csv('train.csv', skiprows=range(1, 101688780))\n",
    "  score = final_fun_2(train_df)\n",
    "  print('score returned is: {}'.format(score))\n",
    "  print('*'*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofIscLgQKe2u",
    "outputId": "f8a3b273-3ac9-4b64-c92a-d90f87e2bd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling Function 1 which will return predictions on test file!!!!\n",
      "***************************************************************************\n",
      "Loading raw data!!!\n",
      "Generating sales and promo data for feature engg\n",
      "Data Collected!!!\n",
      "Shape of sales and promo data is: (167515, 229) and (167515, 245)\n",
      "Generating categorical variables features\n",
      "Categorical variables features generated\n",
      "Extracting features for training using sales information\n",
      "Extracting features for training using promo information\n",
      "Shape of train_x and corresponding train_y is (1340120, 149) & (1340120, 16)\n",
      "Extracting features for prediction on test data using sales information\n",
      "Extracting features for prediction on test data using promo information\n",
      "Shape of test_x is (167515, 149)\n",
      "Making predictions using the pre trained model\n",
      "Prediction done on test data... generating final output\n",
      "Prediction df generated, loading test file and merging results with test file\n",
      "          id       date  store_nbr  item_nbr  onpromotion  unit_sales\n",
      "0  125497040 2017-08-16          1     96995        False    0.236070\n",
      "1  125497041 2017-08-16          1     99197        False    0.375312\n",
      "2  125497042 2017-08-16          1    103501        False    0.000000\n",
      "3  125497043 2017-08-16          1    103520        False    1.205339\n",
      "4  125497044 2017-08-16          1    103665        False    2.255238\n",
      "\n",
      "\n",
      "\n",
      "Calling Function 2 which will return NWRMSLE!!!!\n",
      "***************************************************************************\n",
      "Loading raw data!!!\n",
      "Generating sales and promo data for feature engg\n",
      "Data Collected!!!\n",
      "Shape of sales and promo data is: (167515, 229) and (167515, 245)\n",
      "Generating categorical variables features\n",
      "Categorical variables features generated\n",
      "Extracting features for training using sales information\n",
      "Extracting features for training using promo information\n",
      "Shape of train_x and corresponding train_y is (1340120, 149) & (1340120, 16)\n",
      "Extracting features for prediction on data using sales information\n",
      "Extracting features for prediction on data using promo information\n",
      "Shape of data on which we will predict is (167515, 149)\n",
      "Generating true labels for the data....\n",
      "Making predictions using the pre trained model\n",
      "Predition done, calculating Normalized Weighted Root Mean Squared Log Error!!!\n",
      "score returned is: 0.5208827097261451\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHHbKHJtKe26"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cpu.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
